// Code generated by the FlatBuffers compiler. DO NOT EDIT.

package flatbuffer

import (
	flatbuffers "github.com/google/flatbuffers/go"
)

type Chunk struct {
	_tab flatbuffers.Table
}

func GetRootAsChunk(buf []byte, offset flatbuffers.UOffsetT) *Chunk {
	n := flatbuffers.GetUOffsetT(buf[offset:])
	x := &Chunk{}
	x.Init(buf, n+offset)
	return x
}

func FinishChunkBuffer(builder *flatbuffers.Builder, offset flatbuffers.UOffsetT) {
	builder.Finish(offset)
}

func GetSizePrefixedRootAsChunk(buf []byte, offset flatbuffers.UOffsetT) *Chunk {
	n := flatbuffers.GetUOffsetT(buf[offset+flatbuffers.SizeUint32:])
	x := &Chunk{}
	x.Init(buf, n+offset+flatbuffers.SizeUint32)
	return x
}

func FinishSizePrefixedChunkBuffer(builder *flatbuffers.Builder, offset flatbuffers.UOffsetT) {
	builder.FinishSizePrefixed(offset)
}

func (rcv *Chunk) Init(buf []byte, i flatbuffers.UOffsetT) {
	rcv._tab.Bytes = buf
	rcv._tab.Pos = i
}

func (rcv *Chunk) Table() flatbuffers.Table {
	return rcv._tab
}

func (rcv *Chunk) CompressedSize() uint32 {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(4))
	if o != 0 {
		return rcv._tab.GetUint32(o + rcv._tab.Pos)
	}
	return 0
}

func (rcv *Chunk) MutateCompressedSize(n uint32) bool {
	return rcv._tab.MutateUint32Slot(4, n)
}

func (rcv *Chunk) UncompressedSize() uint32 {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(6))
	if o != 0 {
		return rcv._tab.GetUint32(o + rcv._tab.Pos)
	}
	return 0
}

func (rcv *Chunk) MutateUncompressedSize(n uint32) bool {
	return rcv._tab.MutateUint32Slot(6, n)
}

func (rcv *Chunk) ChunkId() uint64 {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(8))
	if o != 0 {
		return rcv._tab.GetUint64(o + rcv._tab.Pos)
	}
	return 0
}

func (rcv *Chunk) MutateChunkId(n uint64) bool {
	return rcv._tab.MutateUint64Slot(8, n)
}

func (rcv *Chunk) BundleId() uint64 {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(10))
	if o != 0 {
		return rcv._tab.GetUint64(o + rcv._tab.Pos)
	}
	return 0
}

func (rcv *Chunk) MutateBundleId(n uint64) bool {
	return rcv._tab.MutateUint64Slot(10, n)
}

func (rcv *Chunk) BundleOffset() uint32 {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(12))
	if o != 0 {
		return rcv._tab.GetUint32(o + rcv._tab.Pos)
	}
	return 0
}

func (rcv *Chunk) MutateBundleOffset(n uint32) bool {
	return rcv._tab.MutateUint32Slot(12, n)
}

func (rcv *Chunk) FileOffset() uint32 {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(14))
	if o != 0 {
		return rcv._tab.GetUint32(o + rcv._tab.Pos)
	}
	return 0
}

func (rcv *Chunk) MutateFileOffset(n uint32) bool {
	return rcv._tab.MutateUint32Slot(14, n)
}

func ChunkStart(builder *flatbuffers.Builder) {
	builder.StartObject(6)
}
func ChunkAddCompressedSize(builder *flatbuffers.Builder, compressedSize uint32) {
	builder.PrependUint32Slot(0, compressedSize, 0)
}
func ChunkAddUncompressedSize(builder *flatbuffers.Builder, uncompressedSize uint32) {
	builder.PrependUint32Slot(1, uncompressedSize, 0)
}
func ChunkAddChunkId(builder *flatbuffers.Builder, chunkId uint64) {
	builder.PrependUint64Slot(2, chunkId, 0)
}
func ChunkAddBundleId(builder *flatbuffers.Builder, bundleId uint64) {
	builder.PrependUint64Slot(3, bundleId, 0)
}
func ChunkAddBundleOffset(builder *flatbuffers.Builder, bundleOffset uint32) {
	builder.PrependUint32Slot(4, bundleOffset, 0)
}
func ChunkAddFileOffset(builder *flatbuffers.Builder, fileOffset uint32) {
	builder.PrependUint32Slot(5, fileOffset, 0)
}
func ChunkEnd(builder *flatbuffers.Builder) flatbuffers.UOffsetT {
	return builder.EndObject()
}
